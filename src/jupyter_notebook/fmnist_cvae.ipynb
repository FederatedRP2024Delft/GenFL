{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:46:10.601531Z",
     "start_time": "2024-05-27T10:46:10.598192Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:46:11.088895Z",
     "start_time": "2024-05-27T10:46:10.938564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'fmnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:46:11.753011Z",
     "start_time": "2024-05-27T10:46:11.616361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "model = \"cvae\"\n",
    "dataset = \"fmnist\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    cvae_model = torch.load(model_path)\n",
    "else:\n",
    "    cvae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    # try with model sigma\n",
    "    cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    torch.save(cvae_model, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:46:12.435768Z",
     "start_time": "2024-05-27T10:46:12.429069Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:46:31.408117Z",
     "start_time": "2024-05-27T10:46:14.385711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data\n",
    "gen_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:53:59.795232Z",
     "start_time": "2024-05-27T10:46:35.204674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data\n",
    "model = \"exq_v1\"\n",
    "dataset = \"fmnist\"\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "\n",
    "train_loader= DataLoader(gen_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n",
    "    \n",
    "    # torch.save(classifier, model_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:45<10:32, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.260000000000005%\n",
      "Epoch: 1 \tTraining Loss: 0.711327 \t Test Loss: 1.337109 \tF1 Test Macro: 0.610406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:30<09:47, 45.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.075%\n",
      "Epoch: 2 \tTraining Loss: 0.456686 \t Test Loss: 1.312935 \tF1 Test Macro: 0.627798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [02:16<09:07, 45.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.303333333333335%\n",
      "Epoch: 3 \tTraining Loss: 0.352483 \t Test Loss: 1.578677 \tF1 Test Macro: 0.627182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [03:02<08:23, 45.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.262499999999996%\n",
      "Epoch: 4 \tTraining Loss: 0.306485 \t Test Loss: 1.725541 \tF1 Test Macro: 0.623262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [03:47<07:34, 45.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.634%\n",
      "Epoch: 5 \tTraining Loss: 0.275773 \t Test Loss: 1.608604 \tF1 Test Macro: 0.640298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [04:33<06:51, 45.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.91%\n",
      "Epoch: 6 \tTraining Loss: 0.251868 \t Test Loss: 1.669938 \tF1 Test Macro: 0.642543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [05:18<06:02, 45.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.825714285714284%\n",
      "Epoch: 7 \tTraining Loss: 0.234095 \t Test Loss: 1.851493 \tF1 Test Macro: 0.626775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [06:05<05:22, 46.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.985%\n",
      "Epoch: 8 \tTraining Loss: 0.219693 \t Test Loss: 1.628241 \tF1 Test Macro: 0.640790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [06:48<04:30, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.14666666666666%\n",
      "Epoch: 9 \tTraining Loss: 0.205483 \t Test Loss: 1.722201 \tF1 Test Macro: 0.644156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [07:24<04:56, 49.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 36\u001B[0m\n\u001B[1;32m     33\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Forward pass: compute predicted outputs by passing inputs to the model\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m pred_labels\u001B[38;5;241m.\u001B[39mappend(output\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     38\u001B[0m actual_labels\u001B[38;5;241m.\u001B[39mappend(target)\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/src/image_classifier/exq_net_v1.py:149\u001B[0m, in \u001B[0;36mExquisiteNetV1.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 149\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgavg(x)\n\u001B[1;32m    151\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop(x)\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/src/image_classifier/exq_net_v1.py:88\u001B[0m, in \u001B[0;36mDFSEBV1.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     86\u001B[0m y \u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m     87\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpw1(x)\n\u001B[0;32m---> 88\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact1(x)\n\u001B[1;32m     90\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdw1(x)\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:175\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    168\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    170\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 175\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/nn/functional.py:2509\u001B[0m, in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m   2507\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m-> 2509\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2510\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[1;32m   2511\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:31:32.510349Z",
     "start_time": "2024-05-27T10:31:30.621891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.1%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:42:15.304706Z",
     "start_time": "2024-05-27T09:42:15.302884Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
