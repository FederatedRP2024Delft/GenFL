{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T09:23:31.482705Z",
     "start_time": "2024-05-27T09:23:31.479410Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:23:32.395254Z",
     "start_time": "2024-05-27T09:23:32.292445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'fmnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:23:33.985094Z",
     "start_time": "2024-05-27T09:23:33.838700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY50lEQVR4nO3db0yV9/3/8dfRyqltOYchcg6nokVtdamVZU4Z6cq6SAS3mKIusV1v6GJsdNjMf93iErXdlrC5pFm6uHa3NMuq7UyGpt4wURTMNrSp1RizlQhjAyNga+I5iOVo4PO7wW/nu6MgcjiH9+HwfCSfRM51cfh49ZJnL851Pnicc04AAIyxSdYTAABMTAQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYeMR6Avfq7+/XtWvXlJ2dLY/HYz0dAMAIOefU3d2tUCikSZOGvs5JuwBdu3ZNhYWF1tMAAIxSe3u7ZsyYMeT2tPsRXHZ2tvUUAABJMNz385QFaN++fXrqqaf06KOPqqSkRB9//PFDfR4/dgOAzDDc9/OUBOjDDz/Utm3btGfPHn366acqLi5WRUWFrl+/noovBwAYj1wKLFmyxFVXV8c+7uvrc6FQyNXU1Az7ueFw2EliMBgMxjgf4XD4gd/vk34FdOfOHZ0/f17l5eWxxyZNmqTy8nI1Njbet380GlUkEokbAIDMl/QAffHFF+rr61MgEIh7PBAIqLOz8779a2pq5Pf7Y4M74ABgYjC/C27nzp0Kh8Ox0d7ebj0lAMAYSPr7gPLy8jR58mR1dXXFPd7V1aVgMHjf/l6vV16vN9nTAACkuaRfAWVlZWnRokWqq6uLPdbf36+6ujqVlpYm+8sBAMaplKyEsG3bNq1du1bf+MY3tGTJEv32t79VT0+PfvjDH6biywEAxqGUBGjNmjX6/PPPtXv3bnV2duprX/uajh8/ft+NCQCAicvjnHPWk/hfkUhEfr/fehoAgFEKh8Py+XxDbje/Cw4AMDERIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE49YTwDAw3HOjfhzPB5PCmYCJAdXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACRYjBTJYIguYjiUWS53YuAICAJggQAAAE0kP0JtvvimPxxM35s+fn+wvAwAY51LyGtCzzz6rkydP/t8XeYSXmgAA8VJShkceeUTBYDAVTw0AyBApeQ3oypUrCoVCmj17tl599VW1tbUNuW80GlUkEokbAIDMl/QAlZSU6MCBAzp+/Ljeffddtba26oUXXlB3d/eg+9fU1Mjv98dGYWFhsqcEAEhDHpfiNwrcvHlTs2bN0ttvv63169fftz0ajSoajcY+jkQiRAgYRLq/pycRvA8os4XDYfl8viG3p/zugJycHD3zzDNqbm4edLvX65XX6031NAAAaSbl7wO6deuWWlpaVFBQkOovBQAYR5IeoB07dqihoUH//ve/9fe//10rV67U5MmT9corryT7SwEAxrGk/wju6tWreuWVV3Tjxg1Nnz5d3/rWt3T27FlNnz492V8KADCOpfwmhJGKRCLy+/3W0wBSKs3+2SVFIjcUjNVxyMSbHRI9dmN5LIa7CYG14AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEyn/hXQAJgYWFh2Q7schkfml6phzBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATrIYNjNJYrX6MAel+vMdqte50Pw4PgysgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEi5ECQBJlwiKhY4UrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBixAE6c+aMVqxYoVAoJI/HoyNHjsRtd85p9+7dKigo0NSpU1VeXq4rV64ka74AgAwx4gD19PSouLhY+/btG3T73r179c477+i9997TuXPn9Pjjj6uiokK9vb2jniwAIHN43Ch+fZ/H41Ftba2qqqokDVz9hEIhbd++XTt27JAkhcNhBQIBHThwQC+//PKwzxmJROT3+xOdEjDm+A2YyHQejyehzwuHw/L5fENuT+prQK2trers7FR5eXnsMb/fr5KSEjU2Ng76OdFoVJFIJG4AADJfUgPU2dkpSQoEAnGPBwKB2LZ71dTUyO/3x0ZhYWEypwQASFPmd8Ht3LlT4XA4Ntrb262nBAAYA0kNUDAYlCR1dXXFPd7V1RXbdi+v1yufzxc3AACZL6kBKioqUjAYVF1dXeyxSCSic+fOqbS0NJlfCgAwzj0y0k+4deuWmpubYx+3trbq4sWLys3N1cyZM7Vlyxb98pe/1NNPP62ioiLt2rVLoVAodqccAACSJDdCp0+fdpLuG2vXrnXOOdff3+927drlAoGA83q9bunSpa6pqemhnz8cDg/6/AxGug4g0yX6byMcDj/weUf1PqBU4H1AGG/S7J8QkHTj4n1AAAA8LAIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJgY8e8DAgDYS3SF6nRavZ0rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABIuRAsA4lOiiookuYpoKXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZYjBT4H4ku8Ahg5LgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMsBgp0h4LhALJk8i/J4/Hk4KZcAUEADBCgAAAJkYcoDNnzmjFihUKhULyeDw6cuRI3PZ169bJ4/HEjcrKymTNFwCQIUYcoJ6eHhUXF2vfvn1D7lNZWamOjo7YOHTo0KgmCQDIPCO+CWH58uVavnz5A/fxer0KBoMJTwoAkPlS8hpQfX298vPzNW/ePG3atEk3btwYct9oNKpIJBI3AACZL+kBqqys1B//+EfV1dXp17/+tRoaGrR8+XL19fUNun9NTY38fn9sFBYWJntKAIA05HGjeJOFx+NRbW2tqqqqhtznX//6l+bMmaOTJ09q6dKl922PRqOKRqOxjyORCBFCHN4HBNhK9H1A4XBYPp9vyO0pvw179uzZysvLU3Nz86DbvV6vfD5f3AAAZL6UB+jq1au6ceOGCgoKUv2lAADjyIjvgrt161bc1Uxra6suXryo3Nxc5ebm6q233tLq1asVDAbV0tKin/zkJ5o7d64qKiqSOnEAwPg24teA6uvr9Z3vfOe+x9euXat3331XVVVVunDhgm7evKlQKKRly5bpF7/4hQKBwEM9fyQSkd/vH8mUkOF4DQiwlarXgEZ1E0IqEKDxI81OHQApMm5vQgAAYDAECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMeLfB5RJWM0ZAOxwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmMiYxUhZWBRWPB7PiD+H8xXgCggAYIQAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJExi5ECVhJZWDSRBUzTHQusYqS4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATLAYKWCAhTsBroAAAEYIEADAxIgCVFNTo8WLFys7O1v5+fmqqqpSU1NT3D69vb2qrq7WtGnT9MQTT2j16tXq6upK6qQBAOPfiALU0NCg6upqnT17VidOnNDdu3e1bNky9fT0xPbZunWrPvroIx0+fFgNDQ26du2aVq1alfSJAwDGN48bxauhn3/+ufLz89XQ0KCysjKFw2FNnz5dBw8e1Pe//31J0meffaavfvWramxs1De/+c1hnzMSicjv9494LryoCwCpkehv8A2Hw/L5fENuH9VrQOFwWJKUm5srSTp//rzu3r2r8vLy2D7z58/XzJkz1djYOOhzRKNRRSKRuAEAyHwJB6i/v19btmzR888/rwULFkiSOjs7lZWVpZycnLh9A4GAOjs7B32empoa+f3+2CgsLEx0SgCAcSThAFVXV+vy5cv64IMPRjWBnTt3KhwOx0Z7e/uong8AMD4k9EbUzZs369ixYzpz5oxmzJgRezwYDOrOnTu6efNm3FVQV1eXgsHgoM/l9Xrl9XoTmQYAYBwb0RWQc06bN29WbW2tTp06paKiorjtixYt0pQpU1RXVxd7rKmpSW1tbSotLU3OjAEAGWFEV0DV1dU6ePCgjh49quzs7NjrOn6/X1OnTpXf79f69eu1bds25ebmyufz6fXXX1dpaelD3QEHAJg4RnQb9lC34u3fv1/r1q2TNPBG1O3bt+vQoUOKRqOqqKjQ73//+yF/BHcvbsMGgPSSqtuwR/U+oFQgQACQXtLyfUAAACSKAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJhL6jajpKJHVWllBGwDscAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjImMVIE5HIAqYSi5gCQDJwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmJjQi5EmKtFFTEeKRU+BiWGsvqekG66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATLEaaxibqAoUAJgaugAAAJggQAMDEiAJUU1OjxYsXKzs7W/n5+aqqqlJTU1PcPi+++KI8Hk/c2LhxY1InDQAY/0YUoIaGBlVXV+vs2bM6ceKE7t69q2XLlqmnpyduvw0bNqijoyM29u7dm9RJAwDGvxHdhHD8+PG4jw8cOKD8/HydP39eZWVlsccfe+wxBYPB5MwQAJCRRvUaUDgcliTl5ubGPf7+++8rLy9PCxYs0M6dO3X79u0hnyMajSoSicQNAMAE4BLU19fnvve977nnn38+7vE//OEP7vjx4+7SpUvuT3/6k3vyySfdypUrh3yePXv2OEkMBoPByLARDocf2JGEA7Rx40Y3a9Ys197e/sD96urqnCTX3Nw86Pbe3l4XDodjo7293fygMRgMBmP0Y7gAJfRG1M2bN+vYsWM6c+aMZsyY8cB9S0pKJEnNzc2aM2fOfdu9Xq+8Xm8i0wAAjGMjCpBzTq+//rpqa2tVX1+voqKiYT/n4sWLkqSCgoKEJggAyEwjClB1dbUOHjyoo0ePKjs7W52dnZIkv9+vqVOnqqWlRQcPHtR3v/tdTZs2TZcuXdLWrVtVVlamhQsXpuQvAAAYp0byuo+G+Dnf/v37nXPOtbW1ubKyMpebm+u8Xq+bO3eue+ONN4b9OeD/CofD5j+3ZDAYDMbox3Df+z3/PyxpIxKJyO/3W08DADBK4XBYPp9vyO2sBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJF2AXLOWU8BAJAEw30/T7sAdXd3W08BAJAEw30/97g0u+To7+/XtWvXlJ2dLY/HE7ctEomosLBQ7e3t8vl8RjO0x3EYwHEYwHEYwHEYkA7HwTmn7u5uhUIhTZo09HXOI2M4p4cyadIkzZgx44H7+Hy+CX2C/RfHYQDHYQDHYQDHYYD1cfD7/cPuk3Y/ggMATAwECABgYlwFyOv1as+ePfJ6vdZTMcVxGMBxGMBxGMBxGDCejkPa3YQAAJgYxtUVEAAgcxAgAIAJAgQAMEGAAAAmxk2A9u3bp6eeekqPPvqoSkpK9PHHH1tPacy9+eab8ng8cWP+/PnW00q5M2fOaMWKFQqFQvJ4PDpy5Ejcduecdu/erYKCAk2dOlXl5eW6cuWKzWRTaLjjsG7duvvOj8rKSpvJpkhNTY0WL16s7Oxs5efnq6qqSk1NTXH79Pb2qrq6WtOmTdMTTzyh1atXq6ury2jGqfEwx+HFF1+873zYuHGj0YwHNy4C9OGHH2rbtm3as2ePPv30UxUXF6uiokLXr1+3ntqYe/bZZ9XR0REbf/3rX62nlHI9PT0qLi7Wvn37Bt2+d+9evfPOO3rvvfd07tw5Pf7446qoqFBvb+8YzzS1hjsOklRZWRl3fhw6dGgMZ5h6DQ0Nqq6u1tmzZ3XixAndvXtXy5YtU09PT2yfrVu36qOPPtLhw4fV0NCga9euadWqVYazTr6HOQ6StGHDhrjzYe/evUYzHoIbB5YsWeKqq6tjH/f19blQKORqamoMZzX29uzZ44qLi62nYUqSq62tjX3c39/vgsGg+81vfhN77ObNm87r9bpDhw4ZzHBs3HscnHNu7dq17qWXXjKZj5Xr1687Sa6hocE5N/DffsqUKe7w4cOxff75z386Sa6xsdFqmil373Fwzrlvf/vb7sc//rHdpB5C2l8B3blzR+fPn1d5eXnssUmTJqm8vFyNjY2GM7Nx5coVhUIhzZ49W6+++qra2tqsp2SqtbVVnZ2dceeH3+9XSUnJhDw/6uvrlZ+fr3nz5mnTpk26ceOG9ZRSKhwOS5Jyc3MlSefPn9fdu3fjzof58+dr5syZGX0+3Hsc/uv9999XXl6eFixYoJ07d+r27dsW0xtS2i1Geq8vvvhCfX19CgQCcY8HAgF99tlnRrOyUVJSogMHDmjevHnq6OjQW2+9pRdeeEGXL19Wdna29fRMdHZ2StKg58d/t00UlZWVWrVqlYqKitTS0qKf/exnWr58uRobGzV58mTr6SVdf3+/tmzZoueff14LFiyQNHA+ZGVlKScnJ27fTD4fBjsOkvSDH/xAs2bNUigU0qVLl/TTn/5UTU1N+stf/mI423hpHyD8n+XLl8f+vHDhQpWUlGjWrFn685//rPXr1xvODOng5Zdfjv35ueee08KFCzVnzhzV19dr6dKlhjNLjerqal2+fHlCvA76IEMdh9deey325+eee04FBQVaunSpWlpaNGfOnLGe5qDS/kdweXl5mjx58n13sXR1dSkYDBrNKj3k5OTomWeeUXNzs/VUzPz3HOD8uN/s2bOVl5eXkefH5s2bdezYMZ0+fTru17cEg0HduXNHN2/ejNs/U8+HoY7DYEpKSiQprc6HtA9QVlaWFi1apLq6uthj/f39qqurU2lpqeHM7N26dUstLS0qKCiwnoqZoqIiBYPBuPMjEono3LlzE/78uHr1qm7cuJFR54dzTps3b1Ztba1OnTqloqKiuO2LFi3SlClT4s6HpqYmtbW1ZdT5MNxxGMzFixclKb3OB+u7IB7GBx984Lxerztw4ID7xz/+4V577TWXk5PjOjs7rac2prZv3+7q6+tda2ur+9vf/ubKy8tdXl6eu379uvXUUqq7u9tduHDBXbhwwUlyb7/9trtw4YL7z3/+45xz7le/+pXLyclxR48edZcuXXIvvfSSKyoqcl9++aXxzJPrQcehu7vb7dixwzU2NrrW1lZ38uRJ9/Wvf909/fTTrre313rqSbNp0ybn9/tdfX296+joiI3bt2/H9tm4caObOXOmO3XqlPvkk09caWmpKy0tNZx18g13HJqbm93Pf/5z98knn7jW1lZ39OhRN3v2bFdWVmY883jjIkDOOfe73/3OzZw502VlZbklS5a4s2fPWk9pzK1Zs8YVFBS4rKws9+STT7o1a9a45uZm62ml3OnTp52k+8batWudcwO3Yu/atcsFAgHn9Xrd0qVLXVNTk+2kU+BBx+H27dtu2bJlbvr06W7KlClu1qxZbsOGDRn3P2mD/f0luf3798f2+fLLL92PfvQj95WvfMU99thjbuXKla6jo8Nu0ikw3HFoa2tzZWVlLjc313m9Xjd37lz3xhtvuHA4bDvxe/DrGAAAJtL+NSAAQGYiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8P01yfdRGPJrZAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Use VAE to generate some data\n",
    "cvae = ConditionalVae(dim_encoding=3).to('cuda:0')\n",
    "\n",
    "# try with model sigma\n",
    "cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "    training_data=training_data,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    learning_rate=0.001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-27T09:23:38.029020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vl_loss: 30587.828125\n",
      "Finished epoch:  1\n",
      "vl_loss: 57885.77734375\n",
      "Finished epoch:  2\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data\n",
    "gen_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data\n",
    "train_loader= DataLoader(gen_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Assuming 'model' is your model\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1)\n",
    "classifier = classifier.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "apply_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.round(x))])\n",
    "data_dir = '../data/fmnist/'\n",
    "train_dataset = datasets.FashionMNIST(data_dir, train=True, download=True,\n",
    "                               transform=apply_transform)\n",
    "test_dataset = datasets.FashionMNIST(data_dir, train=False, download=True,\n",
    "                              transform=apply_transform)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=True)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
