{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T16:26:26.909906Z",
     "start_time": "2024-05-21T16:26:26.906379Z"
    }
   },
   "source": [
    "import os\n",
    "import torchvision\n",
    "\n",
    "from torch import cuda, device, Tensor, save, load, zeros, vstack, squeeze, zeros_like, where, round\n",
    "from src.plots import plot_vae_training_result, plot_image\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')"
   ],
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:23:57.695710Z",
     "start_time": "2024-05-21T16:23:57.671547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_data = 60000\n",
    "\n",
    "training_data = torchvision.datasets.MNIST(root='../../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(root='../../data/MNIST_test', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "input = training_data.data[:num_data]\n",
    "labels = training_data.targets[:num_data]\n",
    "\n",
    "print(training_data.data[0])"
   ],
   "id": "b76aa94a15dd1c0e",
   "execution_count": 87,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:25:05.745785Z",
     "start_time": "2024-05-21T16:24:05.932987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 64\n",
    "epoch = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epoch}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    vae = load(model_path)\n",
    "else:\n",
    "    vae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    vae_model, vae_loss_li, kl_loss_li = vae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epoch,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    save(vae, model_path)\n",
    "    \n",
    "    # move tensors to cpu before converting to np array\n",
    "    np_kl_loss_li = []\n",
    "    \n",
    "    for output in kl_loss_li:\n",
    "        if isinstance(output, Tensor):\n",
    "            np_kl_loss_li.append(output.cpu().detach().numpy())\n",
    "    \n",
    "    # plot results\n",
    "    plot_vae_training_result(\n",
    "        input=input,\n",
    "        labels=labels,\n",
    "        vae_model=vae_model,\n",
    "        vae_loss_li=vae_loss_li,\n",
    "        kl_loss_li=np_kl_loss_li\n",
    "    )"
   ],
   "id": "415ddc3205ecd96b",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:25:10.318447Z",
     "start_time": "2024-05-21T16:25:10.316309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# images = vae.generate_data(n_samples=1, target_label=0)\n",
    "# print(images.shape)\n",
    "# print(images[0])\n",
    "# print(images[0].max().item())\n",
    "# print(images[0].min().item())"
   ],
   "id": "ef5f4b109ead2b8f",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:25:10.839997Z",
     "start_time": "2024-05-21T16:25:10.721517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_image(training_data.data[:5] / 1.0)\n",
    "print(training_data.data[:1000].mean().item())"
   ],
   "id": "4764a6a2a12f47fd",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:51:16.343394Z",
     "start_time": "2024-05-21T16:51:15.005355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on generated images\n",
    "data_count = 60000\n",
    "ratios = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "global_model = vae\n",
    "            \n",
    "for label_idx, ratio in enumerate(ratios):\n",
    "    num_samples_to_generate = int(data_count * ratio)\n",
    "    output = global_model.generate_data(n_samples=num_samples_to_generate, target_label=label_idx).cpu().detach()\n",
    "\n",
    "    output = where(output < 5e-03, zeros_like(output), output)\n",
    "    output = output * 200\n",
    "    output = output.int()\n",
    "    plot_image(output[:5])\n",
    "    images.append(output)\n",
    "    \n",
    "    \n",
    "    label = zeros((num_samples_to_generate, 10), device=device)\n",
    "    label[:, label_idx] = 1\n",
    "    labels.append(label.cpu().detach())\n",
    "final_images = vstack(images)\n",
    "final_labels = vstack(labels)\n",
    "\n",
    "training_data.data = squeeze(final_images, dim=1)\n",
    "training_data.targets = final_labels.argmax(dim=1)\n",
    "\n",
    "print(training_data.data.shape)\n",
    "print(training_data.targets.shape)\n",
    "print(training_data.data[:1])"
   ],
   "id": "48fdd21624bea58c",
   "execution_count": 112,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:51:16.349844Z",
     "start_time": "2024-05-21T16:51:16.344364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing_data = torchvision.datasets.MNIST(root='../../data/MNIST_train', train=False, download=True,\n",
    "                                                  transform=torchvision.transforms.ToTensor())"
   ],
   "id": "c065b06ade212267",
   "execution_count": 113,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:52:28.253934Z",
     "start_time": "2024-05-21T16:51:17.262963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "epoch = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1)\n",
    "classifier.to(device)\n",
    "classifier.train_model(training_data, testing_data, batch_size=batch_size, learning_rate=learning_rate, epochs=epoch)"
   ],
   "id": "72a33e73f8cef6e2",
   "execution_count": 114,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:52:59.392117Z",
     "start_time": "2024-05-21T16:52:56.772533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test on real data\n",
    "testing_data = torchvision.datasets.MNIST(root='../../data/MNIST_train', train=False, download=True,\n",
    "                                                  transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "accuracy, loss, f1_macro, f1_micro = classifier.test_inference(testing_data, batch_size)\n",
    "print(\"Test on real data\")\n",
    "print(accuracy)\n",
    "print(loss)\n",
    "print(f1_macro)\n",
    "print(f1_micro)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# test on synthetic data\n",
    "data_count = 10000\n",
    "ratios = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "images = []\n",
    "labels = []\n",
    "for label_idx, ratio in enumerate(ratios):\n",
    "    num_samples_to_generate = int(data_count * ratio)\n",
    "    output = global_model.generate_data(n_samples=num_samples_to_generate, target_label=label_idx).cpu().detach()\n",
    "\n",
    "    output = where(output < 5e-03, zeros_like(output), output)\n",
    "    output = output * 200\n",
    "    output = output.int()\n",
    "    images.append(output)\n",
    "    \n",
    "    label = zeros((num_samples_to_generate, 10), device=device)\n",
    "    label[:, label_idx] = 1\n",
    "    labels.append(label.cpu().detach())\n",
    "final_images = vstack(images)\n",
    "final_labels = vstack(labels)\n",
    "\n",
    "testing_data.data = squeeze(final_images, dim=1)\n",
    "testing_data.targets = final_labels.argmax(dim=1)\n",
    "\n",
    "accuracy, loss, f1_macro, f1_micro = classifier.test_inference(testing_data, batch_size)\n",
    "\n",
    "print(\"Test on synthetic data\")\n",
    "print(accuracy)\n",
    "print(loss)\n",
    "print(f1_macro)\n",
    "print(f1_micro)"
   ],
   "id": "1486f2d18194eec6",
   "execution_count": 115,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": " ",
   "id": "75709c1efb40beec",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
