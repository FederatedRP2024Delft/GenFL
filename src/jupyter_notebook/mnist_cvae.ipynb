{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:38.009082Z",
     "start_time": "2024-05-27T10:34:35.851080Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:52.946716Z",
     "start_time": "2024-05-27T10:34:40.207287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'mnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:07<00:00, 1370075.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 291014.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1641425.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 11063024.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:55.174479Z",
     "start_time": "2024-05-27T10:34:54.989272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    cvae_model = torch.load(model_path)\n",
    "else:\n",
    "    cvae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    # try with model sigma\n",
    "    cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    torch.save(cvae_model, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:38:02.940259Z",
     "start_time": "2024-05-27T10:35:05.522305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vl_loss: 24841.130859375\n",
      "Finished epoch:  1\n",
      "vl_loss: 47268.71484375\n",
      "Finished epoch:  2\n",
      "vl_loss: 69200.6640625\n",
      "Finished epoch:  3\n",
      "vl_loss: 89774.8359375\n",
      "Finished epoch:  4\n",
      "vl_loss: 110266.640625\n",
      "Finished epoch:  5\n",
      "vl_loss: 130459.40625\n",
      "Finished epoch:  6\n",
      "vl_loss: 150757.625\n",
      "Finished epoch:  7\n",
      "vl_loss: 170486.640625\n",
      "Finished epoch:  8\n",
      "vl_loss: 190838.90625\n",
      "Finished epoch:  9\n",
      "vl_loss: 210809.921875\n",
      "Finished epoch:  10\n",
      "vl_loss: 230636.96875\n",
      "Finished epoch:  11\n",
      "vl_loss: 250695.296875\n",
      "Finished epoch:  12\n",
      "vl_loss: 270332.25\n",
      "Finished epoch:  13\n",
      "vl_loss: 290011.90625\n",
      "Finished epoch:  14\n",
      "vl_loss: 309347.15625\n",
      "Finished epoch:  15\n",
      "vl_loss: 328808.625\n",
      "Finished epoch:  16\n",
      "vl_loss: 348848.59375\n",
      "Finished epoch:  17\n",
      "vl_loss: 368308.5625\n",
      "Finished epoch:  18\n",
      "vl_loss: 387844.4375\n",
      "Finished epoch:  19\n",
      "vl_loss: 406871.21875\n",
      "Finished epoch:  20\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:38:20.069130Z",
     "start_time": "2024-05-27T10:38:09.855484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data\n",
    "gen_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:45:17.930980Z",
     "start_time": "2024-05-27T10:38:21.938156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data\n",
    "model = \"exq_v1\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "train_loader= DataLoader(gen_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n",
    "    \n",
    "    # torch.save(classifier, model_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/home/neo/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  7%|▋         | 1/15 [00:29<06:47, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.67%\n",
      "Epoch: 1 \tTraining Loss: 0.141749 \t Test Loss: 0.517279 \tF1 Test Macro: 0.876555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:52<05:36, 25.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.23%\n",
      "Epoch: 2 \tTraining Loss: 0.066130 \t Test Loss: 0.580547 \tF1 Test Macro: 0.887286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:19<05:13, 26.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.72%\n",
      "Epoch: 3 \tTraining Loss: 0.036763 \t Test Loss: 0.636404 \tF1 Test Macro: 0.870164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:44<04:42, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.2225%\n",
      "Epoch: 4 \tTraining Loss: 0.027976 \t Test Loss: 0.618212 \tF1 Test Macro: 0.895492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:13<04:30, 27.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.32799999999999%\n",
      "Epoch: 5 \tTraining Loss: 0.028993 \t Test Loss: 0.694400 \tF1 Test Macro: 0.884990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:41<04:07, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.37166666666667%\n",
      "Epoch: 6 \tTraining Loss: 0.022105 \t Test Loss: 0.933533 \tF1 Test Macro: 0.884851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:09<03:41, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.62%\n",
      "Epoch: 7 \tTraining Loss: 0.024602 \t Test Loss: 0.863863 \tF1 Test Macro: 0.899815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:37<03:12, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.7875%\n",
      "Epoch: 8 \tTraining Loss: 0.016904 \t Test Loss: 0.848370 \tF1 Test Macro: 0.899899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:06<02:48, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.21333333333334%\n",
      "Epoch: 9 \tTraining Loss: 0.019498 \t Test Loss: 0.444843 \tF1 Test Macro: 0.925599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:37<02:25, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.437%\n",
      "Epoch: 10 \tTraining Loss: 0.016718 \t Test Loss: 0.480381 \tF1 Test Macro: 0.913877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [05:07<01:57, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.56363636363636%\n",
      "Epoch: 11 \tTraining Loss: 0.011807 \t Test Loss: 0.621824 \tF1 Test Macro: 0.907634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:36<01:27, 29.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.51916666666668%\n",
      "Epoch: 12 \tTraining Loss: 0.012335 \t Test Loss: 0.592077 \tF1 Test Macro: 0.889545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [06:01<00:56, 28.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.42%\n",
      "Epoch: 13 \tTraining Loss: 0.017276 \t Test Loss: 0.820473 \tF1 Test Macro: 0.882063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [06:28<00:27, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.28%\n",
      "Epoch: 14 \tTraining Loss: 0.008880 \t Test Loss: 1.100559 \tF1 Test Macro: 0.873715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:55<00:00, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.422%\n",
      "Epoch: 15 \tTraining Loss: 0.009410 \t Test Loss: 0.599664 \tF1 Test Macro: 0.913986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:45:24.161676Z",
     "start_time": "2024-05-27T10:45:22.419904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.41%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:42:15.304706Z",
     "start_time": "2024-05-27T09:42:15.302884Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
