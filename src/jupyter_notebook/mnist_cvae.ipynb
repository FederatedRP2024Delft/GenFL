{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T08:55:56.141884Z",
     "start_time": "2024-05-27T08:55:56.137990Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T08:55:58.158239Z",
     "start_time": "2024-05-27T08:55:58.053296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'mnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T08:56:02.399937Z",
     "start_time": "2024-05-27T08:56:02.262512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Use VAE to generate some data\n",
    "cvae = ConditionalVae(dim_encoding=3).to('cuda:0')\n",
    "\n",
    "# try with model sigma\n",
    "cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "    training_data=training_data,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    learning_rate=0.001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T08:57:47.655336Z",
     "start_time": "2024-05-27T08:56:15.419944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vl_loss: 25068.396484375\n",
      "Finished epoch:  1\n",
      "vl_loss: 47838.15625\n",
      "Finished epoch:  2\n",
      "vl_loss: 69657.90625\n",
      "Finished epoch:  3\n",
      "vl_loss: 90938.2109375\n",
      "Finished epoch:  4\n",
      "vl_loss: 112353.953125\n",
      "Finished epoch:  5\n",
      "vl_loss: 132945.640625\n",
      "Finished epoch:  6\n",
      "vl_loss: 152877.59375\n",
      "Finished epoch:  7\n",
      "vl_loss: 172757.671875\n",
      "Finished epoch:  8\n",
      "vl_loss: 192679.421875\n",
      "Finished epoch:  9\n",
      "vl_loss: 212912.4375\n",
      "Finished epoch:  10\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T08:58:04.471121Z",
     "start_time": "2024-05-27T08:57:54.343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data\n",
    "gen_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:08:43.330752Z",
     "start_time": "2024-05-27T09:03:52.250936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data\n",
    "train_loader= DataLoader(gen_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Assuming 'model' is your model\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1)\n",
    "classifier = classifier.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "n_epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:29<04:22, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.35000000000001%\n",
      "Epoch: 1 \tTraining Loss: 0.128345 \t Test Loss: 0.693805 \tF1 Test Macro: 0.872109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:57<03:48, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.05%\n",
      "Epoch: 2 \tTraining Loss: 0.062661 \t Test Loss: 0.645976 \tF1 Test Macro: 0.886311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:24<03:15, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.73%\n",
      "Epoch: 3 \tTraining Loss: 0.037985 \t Test Loss: 0.623850 \tF1 Test Macro: 0.899826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:51<02:45, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.2875%\n",
      "Epoch: 4 \tTraining Loss: 0.031346 \t Test Loss: 0.545904 \tF1 Test Macro: 0.908296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:19<02:19, 27.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.75800000000001%\n",
      "Epoch: 5 \tTraining Loss: 0.026474 \t Test Loss: 1.213648 \tF1 Test Macro: 0.865442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:50<01:54, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.66666666666667%\n",
      "Epoch: 6 \tTraining Loss: 0.019858 \t Test Loss: 0.775669 \tF1 Test Macro: 0.883699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:20<01:27, 29.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.99857142857142%\n",
      "Epoch: 7 \tTraining Loss: 0.025582 \t Test Loss: 0.731714 \tF1 Test Macro: 0.909216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [03:51<00:59, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.61875%\n",
      "Epoch: 8 \tTraining Loss: 0.017995 \t Test Loss: 0.909698 \tF1 Test Macro: 0.856579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [04:22<00:30, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.88444444444444%\n",
      "Epoch: 9 \tTraining Loss: 0.020455 \t Test Loss: 0.735734 \tF1 Test Macro: 0.909251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:51<00:00, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.155%\n",
      "Epoch: 10 \tTraining Loss: 0.016927 \t Test Loss: 0.697209 \tF1 Test Macro: 0.914787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:09:02.486971Z",
     "start_time": "2024-05-27T09:09:00.736812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.59%\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:08:54.180035Z",
     "start_time": "2024-05-27T09:08:52.383523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "apply_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.round(x))])\n",
    "data_dir = '../data/mnist/'\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True,\n",
    "                               transform=apply_transform)\n",
    "test_dataset = datasets.MNIST(data_dir, train=False, download=True,\n",
    "                              transform=apply_transform)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=True)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.59%\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
