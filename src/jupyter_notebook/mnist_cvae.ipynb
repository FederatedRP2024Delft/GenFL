{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:38.009082Z",
     "start_time": "2024-05-27T10:34:35.851080Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:52.946716Z",
     "start_time": "2024-05-27T10:34:40.207287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'mnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:34:55.174479Z",
     "start_time": "2024-05-27T10:34:54.989272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    cvae_model = torch.load(model_path)\n",
    "else:\n",
    "    cvae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    # try with model sigma\n",
    "    cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    torch.save(cvae_model, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T10:38:02.940259Z",
     "start_time": "2024-05-27T10:35:05.522305Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:38:20.069130Z",
     "start_time": "2024-05-27T10:38:09.855484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data\n",
    "gen_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:45:17.930980Z",
     "start_time": "2024-05-27T10:38:21.938156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data\n",
    "model = \"exq_v1\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "train_loader= DataLoader(gen_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n",
    "    \n",
    "    # torch.save(classifier, model_path)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:45:24.161676Z",
     "start_time": "2024-05-27T10:45:22.419904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test classifier with real testing data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        outputs = classifier(data)\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Compare with actual classes\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:42:15.304706Z",
     "start_time": "2024-05-27T09:42:15.302884Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 27,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
