{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from src.utils import get_dataset\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import matplotlib.pyplot as plt\n",
    "from src.impute import impute_cvae_naive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:35:48.497398Z",
     "start_time": "2024-06-11T06:35:48.493869Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T06:35:49.246614Z",
     "start_time": "2024-06-11T06:35:49.140504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# binarize the data\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.num_channels = 1\n",
    "        self.iid = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_users = 10\n",
    "        self.dataset = 'mnist'\n",
    "\n",
    "training_data, testing_data, user_groups = get_dataset(args())"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T06:35:50.136306Z",
     "start_time": "2024-06-11T06:35:49.830840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.imshow(training_data[0][0][0], cmap='gray')\n",
    "\n",
    "print(training_data[0][0][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"../../models/local_{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(model_path)\n",
    "    cvae_model = torch.load(model_path)\n",
    "else:\n",
    "    cvae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    # try with model sigma\n",
    "    cvae_model, vae_loss_li, kl_loss_li, reg_loss_li = cvae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    torch.save(cvae_model, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:37:00.034322Z",
     "start_time": "2024-06-11T06:36:59.995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/local_cvae_mnist_32_20_0.001.pt\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vae'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(model_path):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(model_path)\n\u001B[0;32m---> 11\u001B[0m     cvae_model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m     cvae \u001B[38;5;241m=\u001B[39m ConditionalVae(dim_encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/serialization.py:1025\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1023\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1024\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1025\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m                     \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[1;32m   1031\u001B[0m     f_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/serialization.py:1446\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1444\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1445\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1446\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1448\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1449\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[1;32m   1450\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[1;32m   1451\u001B[0m )\n",
      "File \u001B[0;32m~/projects/Federated-Learning-PyTorch/venv/lib/python3.12/site-packages/torch/serialization.py:1439\u001B[0m, in \u001B[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001B[0;34m(self, mod_name, name)\u001B[0m\n\u001B[1;32m   1437\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1438\u001B[0m mod_name \u001B[38;5;241m=\u001B[39m load_module_mapping\u001B[38;5;241m.\u001B[39mget(mod_name, mod_name)\n\u001B[0;32m-> 1439\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'vae'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:38:20.069130Z",
     "start_time": "2024-05-27T10:38:09.855484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate synthetic data and 70000 real testing dataset\n",
    "gen_train_dataset = impute_cvae_naive(k=60000, trained_cvae = cvae_model, initial_dataset = torch.tensor([]))\n",
    "final_testing_data = torch.utils.data.ConcatDataset([training_data, testing_data])\n",
    "print(final_testing_data)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:45:17.930980Z",
     "start_time": "2024-05-27T10:38:21.938156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier on gen data and test on entire 70000 real dataset\n",
    "model = \"exq_v1\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "\n",
    "train_loader= DataLoader(gen_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(final_testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model_path = f\"../../models/local_{model}_{dataset}_{batch_size}_{epochs}_{learning_rate}.pt\"\n",
    "\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "cas_scores = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = classifier(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "             # Compare with actual classes\n",
    "            total_predictions += output.argmax(dim=1).size(0)\n",
    "            # correct_predictions += (predicted == labels).sum().item()\n",
    "            correct_predictions += (output.argmax(dim=1) == target).sum().item()\n",
    "            \n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    cas_scores.append(accuracy)\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100}%')\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))\n",
    "  \n",
    "    print(\"Train losses: \", train_losses)\n",
    "    print(\"Test losses: \", test_losses)\n",
    "    print(\"F1 scores: \", f1_scores)\n",
    "    print(\"CAS scores: \", cas_scores)\n",
    "\n",
    "    # torch.save(classifier, model_path)"
   ],
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
