{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:55.152615Z",
     "start_time": "2024-05-19T14:11:53.188747Z"
    }
   },
   "source": [
    "import os\n",
    "import torchvision\n",
    "\n",
    "from torch import cuda, device, Tensor, save, load, stack, zeros, vstack\n",
    "from src.plots import plot_vae_training_result, plot_image\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "from src.image_classifier.image_classifier import MNISTClassifier\n",
    "from src.utils import frechet_inception_distance\n",
    "from src.sampling import split_dirichlet\n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:55.234638Z",
     "start_time": "2024-05-19T14:11:55.154150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data = torchvision.datasets.MNIST(root='../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(root='../data/MNIST_test', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "\n",
    "input = training_data.data[:60000] / 255.0    # normalizing necessary to make pixels in [0, 1] range for FID\n",
    "labels = training_data.targets[:60000]"
   ],
   "id": "16ee1ea9b79842dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../data/MNIST_train\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/MNIST_test\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:55.330996Z",
     "start_time": "2024-05-19T14:11:55.235418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 100\n",
    "epoch = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"/home/neo/projects/RP_data/models/{model}_{dataset}_{batch_size}_{epoch}_{learning_rate}.pt\"\n",
    "\n",
    "# TODO: add non-IID settings\n",
    "# TODO: save plotting results\n",
    "if os.path.exists(model_path):\n",
    "    vae = load(model_path)\n",
    "else:\n",
    "    vae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    # try with model sigma\n",
    "    vae_model, vae_loss_li, kl_loss_li = vae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epoch,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    save(vae, model_path)\n",
    "    \n",
    "    # move tensors to cpu before converting to np array\n",
    "    np_kl_loss_li = []\n",
    "    \n",
    "    for output in kl_loss_li:\n",
    "        if isinstance(output, Tensor):\n",
    "            np_kl_loss_li.append(output.cpu().detach().numpy())\n",
    "    \n",
    "    # plot results\n",
    "    plot_vae_training_result(\n",
    "        input=input,\n",
    "        labels=labels,\n",
    "        vae_model=vae_model,\n",
    "        vae_loss_li=vae_loss_li,\n",
    "        kl_loss_li=np_kl_loss_li\n",
    "    )"
   ],
   "id": "415ddc3205ecd96b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:55.498405Z",
     "start_time": "2024-05-19T14:11:55.331776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images = vae.generate_data(n_samples=5, target_label=1)\n",
    "plot_image(images)"
   ],
   "id": "8c38d9f63fe4cdfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:56.267001Z",
     "start_time": "2024-05-19T14:11:56.260516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier for performance evaluation\n",
    "model = \"classifier\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 64\n",
    "epoch = 5\n",
    "\n",
    "classifier_path = f\"/home/neo/projects/RP_data/models/{model}_{dataset}_{batch_size}_{epoch}.pt\"\n",
    "\n",
    "if os.path.exists(classifier_path):\n",
    "    classifier = load(classifier_path)\n",
    "else:\n",
    "    classifier = MNISTClassifier(input_size=784, num_classes=10)\n",
    "    classifier.train_model(training_data, batch_size=batch_size, epochs=epoch)\n",
    "    accuracy = classifier.test_model(testing_data)\n",
    "    print(\"Test accuracy: \", accuracy)\n",
    "    save(classifier, classifier_path)"
   ],
   "id": "fe1a2dca5fdd06bb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:11:58.672928Z",
     "start_time": "2024-05-19T14:11:57.229564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate data for testing on classifier\n",
    "# this one stays the same\n",
    "data_count = 10000\n",
    "ratios = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label_idx, ratio in enumerate(ratios):\n",
    "    num_samples_to_generate = int(data_count * ratio)\n",
    "    images.append(vae.generate_data(n_samples=num_samples_to_generate, target_label=label_idx).cpu().detach())\n",
    "    \n",
    "    label = zeros((num_samples_to_generate, 10), device=device)\n",
    "    label[:, label_idx] = 1\n",
    "    labels.append(label.cpu().detach())\n",
    "\n",
    "final_images = vstack(images)\n",
    "final_labels = vstack(labels)\n",
    "\n",
    "assert final_images.shape[0] == final_labels.shape[0]\n",
    "\n",
    "accuracy = classifier.test_model_syn_img_label(final_images, final_labels)\n",
    "print(\"Accuracy: \", accuracy)"
   ],
   "id": "f89dd26fff6ecb7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong count:  229\n",
      "Accuracy:  0.9771\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Determine FID\n",
    "# # generate 500 images\n",
    "# syn_input, _ = vae.generate_data(n_samples=500)\n",
    "# input = input[:500]\n",
    "# \n",
    "# input_rgb = input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# syn_input_rgb = syn_input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# \n",
    "# # compute FID score\n",
    "# fid_score = frechet_inception_distance(input_rgb, syn_input_rgb)\n",
    "# print(\"Frechet Inception Distance: \", fid_score)"
   ],
   "id": "8facfceca09d32d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "e096decd0448907b",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
