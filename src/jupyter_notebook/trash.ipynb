{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T21:17:39.842280Z",
     "start_time": "2024-05-23T21:17:37.623082Z"
    }
   },
   "source": [
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import cuda, device, Tensor, save, load, stack, zeros, vstack, squeeze, tensor, clamp_\n",
    "from src.plots import plot_vae_training_result, plot_image, plot_image_label_two\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "from src.image_classifier.exq_net_v1 import ExquisiteNetV1\n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:17:49.216386Z",
     "start_time": "2024-05-23T21:17:49.177530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_data = 1\n",
    "\n",
    "# training_data is NOT normalized\n",
    "# but no need for further normalization since Dataloader inside the train_model automatically does that\n",
    "training_data = torchvision.datasets.MNIST(root='../../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(root='../../data/MNIST_test', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# not normalized\n",
    "input = training_data.data[:num_data]\n",
    "labels_li = training_data.targets[:num_data]\n",
    "\n",
    "# # not normalized (values 0 ~ 255)\n",
    "# print(training_data.data)"
   ],
   "id": "b76aa94a15dd1c0e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:20:00.005090Z",
     "start_time": "2024-05-23T21:18:01.777385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "model = \"cvae\"\n",
    "dataset = \"mnist\"\n",
    "batch_size = 64\n",
    "epoch = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_path = f\"../../models/{model}_{dataset}_{batch_size}_{epoch}_{learning_rate}.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    cvae = load(model_path)\n",
    "else:\n",
    "    cvae = ConditionalVae(dim_encoding=3).to(device)\n",
    "\n",
    "    vae_model, vae_loss_li, kl_loss_li = cvae.train_model(\n",
    "        training_data=training_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epoch,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    save(cvae, model_path)\n",
    "    \n",
    "    # move tensors to cpu before converting to np array\n",
    "    np_kl_loss_li = []\n",
    "    \n",
    "    for output in kl_loss_li:\n",
    "        if isinstance(output, Tensor):\n",
    "            np_kl_loss_li.append(output.cpu().detach().numpy())\n",
    "    \n",
    "    # plot results\n",
    "    plot_vae_training_result(\n",
    "        input=input,\n",
    "        labels=labels_li,\n",
    "        vae_model=vae_model,\n",
    "        vae_loss_li=vae_loss_li,\n",
    "        kl_loss_li=np_kl_loss_li\n",
    "    )"
   ],
   "id": "415ddc3205ecd96b",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:20:10.202960Z",
     "start_time": "2024-05-23T21:20:10.174930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check original image\n",
    "input, label = training_data[0]\n",
    "\n",
    "print(\"Input shape: \", input.shape)\n",
    "print(input)\n",
    "\n",
    "print(\"Label: \", label)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(151)\n",
    "plt.axis('off')\n",
    "plt.imshow(np.squeeze(input.detach().numpy()), cmap='gray')"
   ],
   "id": "5af3939327e6afdd",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:20:11.202286Z",
     "start_time": "2024-05-23T21:20:11.152340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check reconstructed image\n",
    "input, label = training_data[0]\n",
    "input = input.to(device)\n",
    "label = tensor(label).to(device)\n",
    "output = cvae(input, label)\n",
    "print(\"Reconstructed shape: \", output.shape)\n",
    "print(output)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(151)\n",
    "plt.axis('off')\n",
    "squeezed_img = np.squeeze(output.cpu().detach().numpy())\n",
    "plt.imshow(squeezed_img, cmap='gray')"
   ],
   "id": "f7f2cfc7114c6f8c",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:20:12.115891Z",
     "start_time": "2024-05-23T21:20:12.075799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check randomly sampled image\n",
    "image = cvae.generate_data(n_samples=1, target_label=5)\n",
    "print(\"Randomly sampled shape: \", image.shape)\n",
    "print(image)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(151)\n",
    "plt.axis('off')\n",
    "squeezed_img = np.squeeze(image.cpu().detach().numpy())\n",
    "plt.imshow(squeezed_img, cmap='gray')"
   ],
   "id": "8c38d9f63fe4cdfc",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:20:31.073363Z",
     "start_time": "2024-05-23T21:20:31.069485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # simple classifier for performance evaluation\n",
    "# model = \"classifier\"\n",
    "# dataset = \"mnist\"\n",
    "# batch_size = 64\n",
    "# epoch = 10\n",
    "# \n",
    "# classifier_path = f\"../../models/{model}_{dataset}_{batch_size}_{epoch}.pt\"\n",
    "# \n",
    "# # if os.path.exists(classifier_path):\n",
    "# #     classifier = load(classifier_path)\n",
    "# # else:\n",
    "# classifier = MNISTClassifier(input_size=784, num_classes=10)\n",
    "# classifier.train_model(training_data, batch_size=batch_size, epochs=epoch)\n",
    "# accuracy = classifier.test_model(testing_data)\n",
    "# print(\"Test accuracy: \", accuracy)\n",
    "# save(classifier, classifier_path)"
   ],
   "id": "fe1a2dca5fdd06bb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:30:38.024018Z",
     "start_time": "2024-05-23T21:30:37.416899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate images for training on classifier\n",
    "data_count = 60000\n",
    "ratios = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "batch_size = 60\n",
    "\n",
    "images_li = []\n",
    "labels_li = []\n",
    "for label_idx, ratio in enumerate(ratios):\n",
    "    num_samples_to_generate = int(data_count * ratio)\n",
    "    to_iterate = int(num_samples_to_generate / batch_size)\n",
    "    for i in range(to_iterate):\n",
    "        image = cvae.generate_data(n_samples=batch_size, target_label=label_idx).cpu().detach()\n",
    "        images_li.append(image)\n",
    "        labels_li.append(torch.full((batch_size,), label_idx))\n",
    "\n",
    "print(len(images_li))\n",
    "print(images_li[0].shape)\n",
    "print(images_li[0])\n",
    "\n",
    "print(len(labels_li))\n",
    "print(labels_li[0].shape)\n",
    "# print(labels_li[0])"
   ],
   "id": "48fdd21624bea58c",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:37:39.863424Z",
     "start_time": "2024-05-23T21:37:39.858821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "# shuffle\n",
    "pairs = list(zip(images_li, labels_li))\n",
    "random.shuffle(pairs)\n",
    "shuffled_image_tensors, shuffled_labels = zip(*pairs)\n",
    "images_li = list(shuffled_image_tensors)\n",
    "labels_li = list(shuffled_labels)\n",
    "\n",
    "print(labels_li[0])"
   ],
   "id": "6d36262dfc4e8bc7",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:41:45.759271Z",
     "start_time": "2024-05-23T21:37:40.365974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train CNN classifier on generated images\n",
    "classifier = ExquisiteNetV1(class_num=10, img_channels=1)\n",
    "classifier.to(device)\n",
    "classifier.train_model_syn_image(input_li=images_li, labels_li=labels_li, epochs=20, learning_rate=0.01)"
   ],
   "id": "72a33e73f8cef6e2",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T21:42:08.102523Z",
     "start_time": "2024-05-23T21:42:06.718250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test on real data\n",
    "accuracy, loss, f1_macro, f1_micro = classifier.test_inference(testing_data, batch_size)\n",
    "\n",
    "print(accuracy)\n",
    "print(loss)\n",
    "print(f1_macro)\n",
    "print(f1_micro)\n",
    "\n",
    "# # test on synthetic data\n",
    "# data_count = 10000\n",
    "# ratios = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "# images = []\n",
    "# labels = []\n",
    "# for label_idx, ratio in enumerate(ratios):\n",
    "#     num_samples_to_generate = int(data_count * ratio)\n",
    "#     images.append(\n",
    "#         cvae.generate_data(n_samples=num_samples_to_generate, target_label=label_idx).cpu().detach()\n",
    "#     )\n",
    "#     label = zeros((num_samples_to_generate, 10), device=device)\n",
    "#     label[:, label_idx] = 1\n",
    "#     labels.append(label.cpu().detach())\n",
    "# final_images = vstack(images)\n",
    "# final_labels = vstack(labels)\n",
    "# \n",
    "# testing_data = torchvision.datasets.MNIST(root='../../data/MNIST_train', train=False, download=True,\n",
    "#                                                   transform=torchvision.transforms.ToTensor())\n",
    "# testing_data.data = squeeze(final_images, dim=1)\n",
    "# testing_data.targets = final_labels.argmax(dim=1)\n",
    "# \n",
    "# accuracy, loss, f1_macro, f1_micro = classifier.test_inference(testing_data, batch_size)\n",
    "# \n",
    "# print(accuracy)\n",
    "# print(loss)\n",
    "# print(f1_macro)\n",
    "# print(f1_micro)"
   ],
   "id": "1486f2d18194eec6",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "75709c1efb40beec",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
